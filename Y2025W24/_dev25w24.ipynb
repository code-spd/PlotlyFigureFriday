{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d815db",
   "metadata": {},
   "source": [
    "# NYC Department of Finance\n",
    "## 2023 Parking and Camera Violations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813b090",
   "metadata": {},
   "source": [
    "# Idea\n",
    "- View by parking violation\n",
    "- Include definition and listed fine amounts\n",
    "- Display # violations & total $ paid in 2023\n",
    "- Waterfall breakdown of financial data\n",
    "- Heat map of # violations per hour per day of week\n",
    "- Include # violations per month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb773f38",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.colors as pc\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import requests\n",
    "\n",
    "from models import Violation\n",
    "\n",
    "\n",
    "pio.templates.default = 'plotly_dark'\n",
    "\n",
    "NYC_OPEN_DATA_TOKEN = os.getenv(\"NYC_OPEN_DATA_TOKEN\")\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "\n",
    "END_DATE = pd.Timestamp(2024, 1, 1)\n",
    "TIME_DELTA = pd.Timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af18ea1",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_violation_amounts_by_issue_date(date: pd.Timestamp, limit: int = 100_000, offset: int = 0, year: int = 2023, token: str = NYC_OPEN_DATA_TOKEN) -> list[dict]:\n",
    "    date_iso = date.isoformat(timespec='milliseconds')\n",
    "    date_us = date.strftime('%m/%d/%Y')\n",
    "\n",
    "    url = \"https://data.cityofnewyork.us/resource/nc67-uf89.json\"\n",
    "    params = {\n",
    "        \"$where\": f\"issue_date in('{date_us}', '{date_iso}')\",\n",
    "        \"$select\": \"summons_number, issue_date, violation_time, violation, fine_amount, penalty_amount, interest_amount, reduction_amount, payment_amount, amount_due, violation_status, license_type, state, issuing_agency\",\n",
    "        \"$order\": \"summons_number ASC\",\n",
    "        \"$limit\": limit,\n",
    "        \"$offset\": offset\n",
    "    }\n",
    "    headers = {\"X-App-Token\": token}\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def persist_as_parquet(response_json, filepath: Path, overwrite: bool = False) -> None:\n",
    "    if filepath.exists() and not overwrite:\n",
    "        raise FileExistsError(f\"The filename {filepath.name!r} already exists in directory {filepath.parent!r}!\"\n",
    "                              \"To overwrite file, set `overwrite=True`.\")\n",
    "    df_json = pd.DataFrame(response_json)\n",
    "    df_json.to_parquet(filepath, index=False, compression='snappy')\n",
    "\n",
    "\n",
    "def load_parquets_by_month(month: int, input_dir: Path, year: int = 2023) -> pd.DataFrame:\n",
    "    hours = ['12 AM'] + [f'{h} AM' for h in range(1, 12)] + ['12 PM'] + [f'{h} PM' for h in range(1, 12)]\n",
    "    days_map = {6: 'Sun', 0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri', 5: 'Sat'}\n",
    "    dff = pd.concat([pd.read_parquet(f) for f in input_dir.glob(f'nc67-uf89_issue-date_{year}-{month:0>2}*.parquet')])\n",
    "\n",
    "    # Assign data types\n",
    "    dff['issue_date'] = pd.to_datetime(dff['issue_date'], format='mixed', errors='coerce')\n",
    "    dff['violation_time'] = pd.to_datetime(dff['violation_time']+'M', format='%I:%M%p', errors='coerce')\n",
    "\n",
    "    for col in ['fine_amount', 'penalty_amount', 'interest_amount', 'reduction_amount', 'payment_amount', 'amount_due']:\n",
    "        dff[col] = dff[col].astype(float)\n",
    "\n",
    "    # Drop blanks\n",
    "    dff.dropna(subset=['issue_date', 'violation_time', 'violation', 'fine_amount'], inplace=True)\n",
    "\n",
    "    # Get hour and day of week\n",
    "    dff['hour'] = dff['violation_time'].dt.strftime('%I %p').str.replace(r'^0', '', regex=True)\n",
    "    dff['hour'] = pd.Categorical(dff['hour'], categories=hours, ordered=True)\n",
    "\n",
    "    dff['day_of_week'] = dff['issue_date'].dt.day_of_week.map(days_map)\n",
    "    dff['day_of_week'] = pd.Categorical(dff['day_of_week'], categories=days_map.values(), ordered=True)\n",
    "\n",
    "    # Tidy up\n",
    "    dff['violation_time'] = dff['violation_time'].dt.time  # Drop erroneous date-component\n",
    "\n",
    "    return dff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db383c",
   "metadata": {},
   "source": [
    "# Data\n",
    "- Original dataset provided is missing records\n",
    "- Will use NYC Open Data API to find records containing \"2023\" in the `issue_date` column\n",
    "- Initial query reveals 16,526,342 records available\n",
    "- `issue_data` column contains mixed timestamp formats:\n",
    "    - US-style: `mm/dd/yyy`\n",
    "    - ISO 8601: `yyyy-mm-ddThh:mm:ss.fff`\n",
    "- Will loop through each calendar day in 2023 and store raw results as parquet\n",
    "- Transform and compile daily results into monthly parquet datasets for aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c717e2",
   "metadata": {},
   "source": [
    "## Query\n",
    "- Takes ~60 minutes w/ 2-sec sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(2023, 1, 1)\n",
    "errors = []\n",
    "\n",
    "while date < END_DATE:\n",
    "    try:\n",
    "        data = fetch_violation_amounts_by_issue_date(date=date)\n",
    "\n",
    "        if data:\n",
    "            data_fp = DATA_DIR / f\"nc67-uf89_issue-date_{date.strftime('%Y-%m-%d')}_v2.parquet\"\n",
    "            persist_as_parquet(response_json=data, filepath=data_fp, overwrite=False)\n",
    "            print(f\"Saved data for DATE {date.strftime('%Y-%m-%d')}\")\n",
    "        else:\n",
    "            message = f\"NO DATA for DATE {date.strftime('%Y-%m-%d')}\"\n",
    "            print(message)\n",
    "            errors.append(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"EXCEPTION encountered for DATE {date.strftime('%Y-%m-%d')}: {e!r}\"\n",
    "        print(message)\n",
    "        errors.append(message)\n",
    "\n",
    "    finally:\n",
    "        date += TIME_DELTA\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c62ad",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc121a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 13):\n",
    "    df_m = load_parquets_by_month(month, DATA_DIR)\n",
    "\n",
    "    output_fp = DATA_DIR / f'nc67-uf89_month_2023-{month:0>2}_v2.parquet'\n",
    "    df_m.to_parquet(output_fp, index=False, compression='snappy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cca5a",
   "metadata": {},
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c15f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / 'nyc_parking_violation_codes.json', 'r', encoding='utf-8') as fp:\n",
    "    violation_details = json.load(fp)\n",
    "\n",
    "violations = {v['description']: Violation.from_dict(v) for v in violation_details}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60405356",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 13):\n",
    "    df_m = pd.read_parquet(DATA_DIR / f\"nc67-uf89_month_2023-{month:0>2}_v2.parquet\")\n",
    "\n",
    "    for col in ['violation_status', 'issuing_agency', 'state', 'license_type']:\n",
    "        df_m[col] = df_m[col].fillna('none')\n",
    "\n",
    "    df_m['period'] = df_m['issue_date'].dt.to_period('W').dt.start_time.dt.date.transform(lambda x: x.isoformat())\n",
    "    df_m['count'] = 1\n",
    "\n",
    "    counts = df_m['violation'].value_counts()\n",
    "    period_count = df_m.groupby(['violation', 'period'])['count'].sum()\n",
    "    period_fine = df_m.groupby(['violation', 'period'])['fine_amount'].sum()\n",
    "    amounts = df_m.groupby('violation')[[col for col in df_m.columns if col.find('amount')!= -1]].sum().round(0).astype(int)\n",
    "    hour_dow_counts = df_m.groupby(['violation', 'hour', 'day_of_week'], observed=False)['count'].sum().astype(int).reset_index().pivot(index=['violation', 'hour'], columns='day_of_week', values='count')\n",
    "\n",
    "    statuses = df_m.groupby(['violation', 'violation_status'])['count'].sum()\n",
    "    agencies = df_m.groupby(['violation', 'issuing_agency'])['count'].sum()\n",
    "    states = df_m.groupby(['violation', 'state'])['count'].sum()\n",
    "    license_types = df_m.groupby(['violation', 'license_type'])['count'].sum()\n",
    "\n",
    "    # Update Violation objects\n",
    "    for v_key in df_m['violation'].unique():\n",
    "        if v_key not in violations.keys():\n",
    "            continue\n",
    "\n",
    "        v = violations[v_key]\n",
    "\n",
    "        v.total_count += int(counts.loc[v_key])\n",
    "        v.period_count.update(period_count.loc[v_key].to_dict())\n",
    "        v.period_fine.update(period_fine.loc[v_key].to_dict())\n",
    "\n",
    "        v.total_fine += amounts.loc[v_key].get('fine_amount').item()\n",
    "        v.total_penalty += amounts.loc[v_key].get('penalty_amount').item()\n",
    "        v.total_interest += amounts.loc[v_key].get('interest_amount').item()\n",
    "        v.total_reduction += amounts.loc[v_key].get('reduction_amount').item()\n",
    "        v.total_payment += amounts.loc[v_key].get('payment_amount').item()\n",
    "        v.total_due += amounts.loc[v_key].get('amount_due').item()\n",
    "\n",
    "        v.hour_dow_counts += hour_dow_counts.loc[v_key].values\n",
    "\n",
    "        v.statuses = dict(Counter(statuses.loc[v_key].to_dict()) + Counter(v.statuses))\n",
    "        v.agencies = dict(Counter(agencies.loc[v_key].to_dict()) + Counter(v.agencies))\n",
    "        v.states = dict(Counter(states.loc[v_key].to_dict()) + Counter(v.states))\n",
    "        v.license_types = dict(Counter(license_types.loc[v_key].to_dict()) + Counter(v.license_types))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_ALL = Violation(\n",
    "    code=0,\n",
    "    description=\"ALL VIOLATIONS\",\n",
    "    definition=\"An aggregation of all parking and camera violations for 2023 as of June 18, 2025. Records missing issue date, violation, or fine amount are omitted along with records assigned to \\\"BLUE ZONE\\\", which is no longer a valid NYC violation.\",\n",
    "    fine_amount_manhattan_96st_and_below=[],\n",
    "    fine_amount_all_other_areas=[]\n",
    ")\n",
    "\n",
    "for v in violations.values():\n",
    "    V_ALL.total_count += v.total_count\n",
    "    \n",
    "    V_ALL.period_count = dict(Counter(V_ALL.period_count) + Counter(v.period_count))\n",
    "    V_ALL.period_count = dict(sorted(V_ALL.period_count.items()))  # ensure ordered consecutively    \n",
    "\n",
    "    V_ALL.period_fine = dict(Counter(V_ALL.period_fine) + Counter(v.period_fine))\n",
    "    V_ALL.period_fine = dict(sorted(V_ALL.period_fine.items()))  # ensure ordered consecutively\n",
    "    \n",
    "    V_ALL.total_fine += v.total_fine\n",
    "    V_ALL.total_penalty += v.total_penalty\n",
    "    V_ALL.total_interest += v.total_interest\n",
    "    V_ALL.total_reduction += v.total_reduction\n",
    "    V_ALL.total_payment += v.total_payment\n",
    "    V_ALL.total_due += v.total_due\n",
    "    V_ALL.hour_dow_counts = V_ALL.hour_dow_counts + v.hour_dow_counts\n",
    "\n",
    "    V_ALL.fine_amount_manhattan_96st_and_below += v.fine_amount_manhattan_96st_and_below\n",
    "    V_ALL.fine_amount_manhattan_96st_and_below = sorted(list(set(V_ALL.fine_amount_manhattan_96st_and_below)))\n",
    "\n",
    "    V_ALL.fine_amount_all_other_areas += v.fine_amount_all_other_areas\n",
    "    V_ALL.fine_amount_all_other_areas = sorted(list(set(V_ALL.fine_amount_all_other_areas)))\n",
    "\n",
    "    V_ALL.statuses = dict(Counter(V_ALL.statuses) + Counter(v.statuses))\n",
    "    V_ALL.statuses = dict(sorted(V_ALL.statuses.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    V_ALL.agencies = dict(Counter(V_ALL.agencies) + Counter(v.agencies))\n",
    "    V_ALL.agencies = dict(sorted(V_ALL.agencies.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    V_ALL.states = dict(Counter(V_ALL.states) + Counter(v.states))\n",
    "    V_ALL.states = dict(sorted(V_ALL.states.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    V_ALL.license_types = dict(Counter(V_ALL.license_types) + Counter(v.license_types))\n",
    "    V_ALL.license_types = dict(sorted(V_ALL.license_types.items(), key=lambda x: x[1], reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed2742",
   "metadata": {},
   "source": [
    "## Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ced94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"nyc_parking_violation_data.json\", 'w', encoding='utf-8') as f:\n",
    "    all_violations = [V_ALL] + list(violations.values())\n",
    "    json.dump([v.to_dict() for v in all_violations], f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
